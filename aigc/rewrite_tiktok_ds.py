# -*- coding: utf-8 -*-
"""
Rewrite TikTok scripts via DeepSeek Platform API (OpenAI-compatible).
- Preserves languages per side (no translation): TTS keeps TTS languages; Caption keeps Caption languages.
- TTS outputs -> folder of --tts; Caption outputs -> folder of --caption.
- Streaming with compact mode; robust JSON parsing; supports N variants per request.
"""

import os, re, json, time, argparse, sys
from pathlib import Path
from typing import List, Tuple, Dict, Any
from openai import OpenAI

HASHTAG_PATTERN = re.compile(r"#([\w\-\u4e00-\u9fff]+)", re.UNICODE)

def preprocess_tts_text(text):
    """
    Preprocess TTS text by converting all punctuation marks to newlines.
    This is necessary because batch-generated TTS documents currently cannot handle automatic line breaks.
    """
    if not text:
        return text
    
    # Define all common punctuation marks including Chinese and English punctuation
    # Using a single string to avoid any spacing issues
    punctuation_marks = (
        'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€'  # Chinese punctuation
        ',.!?;:'  # English punctuation  
        '-â€”â€¦~ï½'  # Dashes and ellipsis
        'ï¼ˆï¼‰()'  # Parentheses
        '[]ã€ã€‘'  # Brackets
        'ã€Šã€‹ã€ˆã€‰'  # Angle brackets
        'ã€Œã€ã€ã€'  # Japanese quotes
        '""'''  # Smart quotes
        '"'  # Regular double quotes (removed single quote to preserve contractions/possessives)
        '`/|\\'  # Other marks
    )
    
    # Create pattern - escape special regex characters
    punctuation_pattern = '[' + re.escape(punctuation_marks) + ']'
    
    # Replace all punctuation marks with newlines
    processed_text = re.sub(punctuation_pattern, '\n', text)
    
    # Split into lines and clean each line
    lines = processed_text.split('\n')
    # Remove empty lines and strip whitespace from each line
    cleaned_lines = [line.strip() for line in lines if line.strip()]
    
    # Join back with newlines
    processed_text = '\n'.join(cleaned_lines)
    
    return processed_text

# ---------- IO helpers ----------

def read_text(path: Path) -> str:
    with path.open("r", encoding="utf-8") as f:
        return f.read().strip()

def split_caption_and_tags(caption: str) -> Tuple[str, List[str]]:
    tags = [f"#{m.group(1)}" for m in HASHTAG_PATTERN.finditer(caption)]
    body = HASHTAG_PATTERN.sub("", caption)
    body = re.sub(r"\s{2,}", " ", body).strip()
    return body, tags

def style_preset(i: int) -> str:
    presets = [
        "é’©å­=åé—®å¥ï¼›è¯­æ°”=å£è¯­åŒ–ï¼›å¥é•¿=çŸ­ï¼›èŠ‚å¥=å¿«ï¼›",
        "é’©å­=æ•°å­—å¼€å¤´ï¼›è¯­æ°”=çƒ­æƒ…ï¼›å¥é•¿=çŸ­ï¼›èŠ‚å¥=ä¸­ï¼›",
        "é’©å­=æ‚¬å¿µï¼›è¯­æ°”=å¹³å®å¯ä¿¡ï¼›å¥é•¿=ä¸­ï¼›èŠ‚å¥=æ…¢ï¼›",
        "é’©å­=å¯¹æ¯”ï¼›è¯­æ°”=å¥½å¥‡æ¢ç´¢ï¼›å¥é•¿=çŸ­ï¼›èŠ‚å¥=å¿«ï¼›",
        "é’©å­=å‘½ä»¤å¼ï¼›è¯­æ°”=ç›´æ¥æœ‰åŠ›ï¼›å¥é•¿=çŸ­ï¼›èŠ‚å¥=å¿«ï¼›",
    ]
    return presets[i % len(presets)]

# ---------- Light language fingerprint (for model hint) ----------

def lang_signature(text: str) -> str:
    sig = []
    if re.search(r"[\u4e00-\u9fff]", text): sig.append("Chinese")
    if re.search(r"[A-Za-z]", text): sig.append("Latin")
    if re.search(r"[\u3040-\u309f\u30a0-\u30ff]", text): sig.append("Japanese")
    if re.search(r"[\uac00-\ud7af]", text): sig.append("Korean")
    if re.search(r"[\u0e00-\u0e7f]", text): sig.append("Thai")
    if re.search(r"[\u0400-\u04FF]", text): sig.append("Cyrillic")
    if re.search(r"[\u0600-\u06FF]", text): sig.append("Arabic")
    if re.search(r"[0-9]", text): sig.append("Digits")
    if re.search(r"[\U0001F300-\U0001FAFF]", text): sig.append("Emoji")
    return ", ".join(sig) if sig else "Unknown"

# ---------- JSON sanitization ----------

def strip_code_fences(s: str) -> str:
    s = s.strip()
    if s.startswith("```"):
        s = re.sub(r"^```(?:json)?\s*|\s*```$", "", s, flags=re.DOTALL)
    # Also clean up any trailing spaces on each line which can cause JSON parsing issues
    lines = s.split('\n')
    cleaned_lines = [line.rstrip() for line in lines]
    s = '\n'.join(cleaned_lines)
    return s

def normalize_quotes(s: str) -> str:
    # Don't normalize quotes that are inside JSON string values
    # Only normalize smart quotes to regular quotes, but leave Chinese quotes as-is
    # since they don't conflict with JSON syntax
    s = s.replace(""", '"').replace(""", '"').replace("'", "'").replace("'", "'")
    # Don't replace Chinese quotation marks as they're valid inside JSON strings
    # s = s.replace(""", '"').replace(""", '"')  # Commented out - keep Chinese quotes
    return s

def escape_newlines_in_strings(s: str) -> str:
    out, in_str, esc = [], False, False
    for ch in s:
        if in_str:
            if esc: out.append(ch); esc = False
            else:
                if ch == "\\": out.append(ch); esc = True
                elif ch == '"': out.append(ch); in_str = False
                elif ch in ("\n", "\r"): out.append("\\n")
                else: out.append(ch)
        else:
            if ch == '"': out.append(ch); in_str = True; esc = False
            else: out.append(ch)
    return "".join(out)

def trim_to_complete_json(s: str) -> str:
    # Keep up to last complete {...} or [...] at top level
    depth_obj = depth_arr = 0
    last_complete = -1
    in_str = False; esc = False
    for i, ch in enumerate(s):
        if in_str:
            if esc: esc = False
            else:
                if ch == "\\": esc = True
                elif ch == '"': in_str = False
        else:
            if ch == '"': in_str = True
            elif ch == "{": depth_obj += 1
            elif ch == "}":
                depth_obj -= 1
                if depth_obj == 0 and depth_arr == 0: last_complete = i
            elif ch == "[": depth_arr += 1
            elif ch == "]":
                depth_arr -= 1
                if depth_arr == 0 and depth_obj == 0: last_complete = i
    return s[: last_complete + 1] if last_complete != -1 else s

def robust_parse_json(raw: str) -> Any:
    s = strip_code_fences(raw)
    s = normalize_quotes(s)
    s = escape_newlines_in_strings(s)
    try:
        return json.loads(s)
    except json.JSONDecodeError as e:
        # Try trimming to complete JSON
        try:
            s2 = trim_to_complete_json(s)
            return json.loads(s2)
        except Exception:
            # If still failing, try one more time with aggressive cleaning
            # Remove any trailing content after the last }
            last_brace = s.rfind('}')
            if last_brace != -1:
                s3 = s[:last_brace + 1]
                try:
                    return json.loads(s3)
                except Exception:
                    pass
            raise e

# ---------- Streaming printer ----------

class StreamPrinter:
    def __init__(self, mode: str = "compact", logfile: Path | None = None):
        self.mode = mode
        self.buf = []
        self.last_flush = time.time()
        self.logfile = logfile
        if logfile:
            logfile.parent.mkdir(parents=True, exist_ok=True)
            logfile.write_text("", encoding="utf-8")

    def _write_log(self, text: str):
        if self.logfile:
            with self.logfile.open("a", encoding="utf-8") as f:
                f.write(text)

    def add(self, text: str):
        if not text:
            return
        self._write_log(text)
        if self.mode == "raw":
            sys.stdout.write(text); sys.stdout.flush()
            return
        # compact: collapse whitespace & flush in chunks
        self.buf.append(text)
        now = time.time()
        if (now - self.last_flush) > 0.05 or len("".join(self.buf)) > 400:
            chunk = "".join(self.buf)
            chunk = re.sub(r"[ \t\r\n]+", " ", chunk)
            sys.stdout.write(chunk); sys.stdout.flush()
            self.buf = []
            self.last_flush = now

    def close(self):
        if self.buf:
            chunk = "".join(self.buf)
            chunk = re.sub(r"[ \t\r\n]+", " ", chunk)
            sys.stdout.write(chunk); sys.stdout.flush()
            self.buf = []

# ---------- API wrappers ----------

def call_stream(client: OpenAI, model: str, system_prompt: str, user_prompt: str,
                show_reasoning: bool, max_tokens: int, temperature: float,
                stream_style: str, stream_log: Path | None) -> str:
    print("\n===== streaming started =====", flush=True)
    if model == "deepseek-reasoner" and show_reasoning:
        print("----- reasoning (live) -----", flush=True)
    else:
        print("----- content (live) -----", flush=True)

    content_buf: List[str] = []
    sp = StreamPrinter(mode=stream_style, logfile=stream_log)

    stream = client.chat.completions.create(
        model=model,
        messages=[{"role":"system","content":system_prompt}, {"role":"user","content":user_prompt}],
        response_format={"type":"json_object"},
        stream=True,
        max_tokens=max_tokens,
        temperature=temperature,
    )
    for chunk in stream:
        delta = chunk.choices[0].delta
        rc = getattr(delta, "reasoning_content", None)
        if rc and show_reasoning:
            sp.add(rc)
        part = getattr(delta, "content", None)
        if part:
            sp.add(part)
            content_buf.append(part)

    sp.close()
    print("\n===== streaming done =====\n", flush=True)
    return "".join(x for x in content_buf if x)

def call_no_stream(client: OpenAI, model: str, system_prompt: str, user_prompt: str,
                   max_tokens: int, temperature: float) -> str:
    resp = client.chat.completions.create(
        model=model,
        messages=[{"role":"system","content":system_prompt}, {"role":"user","content":user_prompt}],
        response_format={"type":"json_object"},
        max_tokens=max_tokens,
        temperature=temperature,
    )
    return resp.choices[0].message.content or ""

# ---------- Main ----------

def main():
    ap = argparse.ArgumentParser(description="Rewrite TikTok scripts - supports both TTS+Caption and Caption-only modes")
    ap.add_argument("--tts", required=False, help="TTS file path (optional - omit for caption-only mode)")
    ap.add_argument("--caption", required=True, help="Caption file path (required)")
    ap.add_argument("-n","--num", type=int, default=3, help="Total variants to generate")
    ap.add_argument("--variants-per-request", type=int, default=1, help="How many variants per API request")
    ap.add_argument("--model", default="deepseek-chat")
    ap.add_argument("--base_url", default="https://api.deepseek.com")
    ap.add_argument("--temperature", type=float, default=0.8)
    ap.add_argument("--stream", action="store_true")
    ap.add_argument("--no-reasoning", action="store_true")
    ap.add_argument("--stream-style", choices=["raw","compact"], default="compact")
    ap.add_argument("--stream-log", default=None, help="Optional path to save full stream (reasoning+content)")
    ap.add_argument("--max_tokens", type=int, default=3072)
    ap.add_argument("--retries", type=int, default=2, help="Retries on malformed JSON")
    ap.add_argument("--no-tts", action="store_true", help="Caption-only mode - skip TTS generation, only process captions")
    args = ap.parse_args()

    api_key = os.environ.get("DEEPSEEK_API_KEY")
    if not api_key:
        raise RuntimeError("è¯·å…ˆè®¾ç½®ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY")

    # Initialize OpenAI client with error handling for version compatibility
    try:
        client = OpenAI(api_key=api_key, base_url=args.base_url)
    except TypeError as e:
        if "proxies" in str(e):
            # Fallback for older OpenAI client versions
            print(f"âš ï¸ OpenAI client version compatibility issue: {e}")
            print("ğŸ”„ Trying fallback initialization...")
            try:
                # Try simpler initialization for older versions
                client = OpenAI(api_key=api_key)
                client.base_url = args.base_url
            except Exception as fallback_error:
                raise RuntimeError(f"Failed to initialize OpenAI client. Please update openai package: pip install openai>=1.40.0") from fallback_error
        else:
            raise

    cap_path = Path(args.caption).resolve()
    cap_dir = cap_path.parent

    cap_src = read_text(cap_path)
    cap_body, tags = split_caption_and_tags(cap_src)
    cap_sig = lang_signature(cap_body)

    # Handle TTS if provided
    tts_src = None
    tts_sig = None
    tts_dir = None
    if args.tts and not args.no_tts:
        tts_path = Path(args.tts).resolve()
        tts_dir = tts_path.parent
        tts_src = read_text(tts_path)
        tts_sig = lang_signature(tts_src)

    # Build prompts
    if tts_src:
        language_rules = (
            "â€¢ è¯­è¨€ä¿æŒï¼šTTS ä»…æŒ‰ TTS åŸæ–‡çš„è¯­è¨€/æ··åˆè¯­è¨€æ”¹å†™ï¼›Caption ä»…æŒ‰ Caption æ­£æ–‡çš„è¯­è¨€/æ··åˆè¯­è¨€æ”¹å†™ï¼›"
            "ç¦æ­¢ç¿»è¯‘æˆ–è·¨è¯­è¨€æ›¿æ¢ï¼›ä¿æŒåŸæœ‰ code-switching ä½ç½®ä¸æ¯”ä¾‹ï¼›å“ç‰Œ/åœ°å/äººå/å‹å·/æ•°å­—/è´§å¸ç¬¦å·/Emoji åŸæ ·ä¿ç•™ã€‚"
        )
        base_rules = (
            "â€¢ TTSï¼šå£è¯­åŒ–ã€æ˜“å¿µï¼Œé•¿åº¦ä¸åŸç¨¿æ¥è¿‘ï¼ˆÂ±20%ï¼‰ï¼›é¿å…æ‹—å£ä¸è¿‡é•¿å¥ã€‚\n"
            "â€¢ Captionï¼šé¦–å¥åšå¼ºé’©å­ï¼ˆä¸­æ–‡â‰¤10å­—ï¼›è‹±æ–‡â‰¤6 wordsï¼‰ï¼Œä¸å¾—æ–°å¢æ ‡ç­¾ï¼›ä¸å¾—åœ¨æ­£æ–‡ä¸­å‡ºç°#æ ‡ç­¾ã€‚\n"
            "â€¢ åªè¾“å‡ºåˆæ³• JSONã€‚"
        )
    else:
        language_rules = (
            "â€¢ è¯­è¨€ä¿æŒï¼šCaption ä»…æŒ‰ Caption æ­£æ–‡çš„è¯­è¨€/æ··åˆè¯­è¨€æ”¹å†™ï¼›"
            "ç¦æ­¢ç¿»è¯‘æˆ–è·¨è¯­è¨€æ›¿æ¢ï¼›ä¿æŒåŸæœ‰ code-switching ä½ç½®ä¸æ¯”ä¾‹ï¼›å“ç‰Œ/åœ°å/äººå/å‹å·/æ•°å­—/è´§å¸ç¬¦å·/Emoji åŸæ ·ä¿ç•™ã€‚"
        )
        base_rules = (
            "â€¢ Captionï¼šé¦–å¥åšå¼ºé’©å­ï¼ˆä¸­æ–‡â‰¤10å­—ï¼›è‹±æ–‡â‰¤6 wordsï¼‰ï¼Œä¸å¾—æ–°å¢æ ‡ç­¾ï¼›ä¸å¾—åœ¨æ­£æ–‡ä¸­å‡ºç°#æ ‡ç­¾ã€‚\n"
            "â€¢ åªè¾“å‡ºåˆæ³• JSONã€‚"
        )

    def build_user_prompt(batch_index: int, expect_k: int) -> str:
        # If expect_k == 1, single object; else variants array with exact length
        if tts_src:
            template_single = "{\n  \"tts\": \"æ”¹å†™åçš„ TTS æ–‡æ¡ˆï¼ˆä¿æŒåŸè¯­è¨€/æ··åˆè¯­è¨€ï¼Œä¸ç¿»è¯‘ï¼‰\",\n  \"caption\": \"æ”¹å†™åçš„ä¸‹æ–¹æ–‡æ¡ˆï¼ˆä¿æŒåŸè¯­è¨€/æ··åˆè¯­è¨€ï¼Œä¸ç¿»è¯‘ï¼›ä¸å«ä»»ä½•æ ‡ç­¾ï¼‰\"\n}"
            template_multi = "{\n  \"variants\": [\n    {\"tts\": \"...\", \"caption\": \"...\"}\n  ]\n}"
            
            return (
                (f"ã€ä»»åŠ¡ã€‘æ­¤è½®ç”Ÿæˆ {expect_k} ä¸ªäº’ä¸é‡å¤çš„å˜ä½“ï¼›"
                 f"{'ç›´æ¥è¿”å›å•ä¸ªJSONå¯¹è±¡' if expect_k==1 else 'è¿”å›ä¸€ä¸ªåŒ…å« variants æ•°ç»„çš„ JSON å¯¹è±¡ï¼Œvariants é•¿åº¦å¿…é¡»ç²¾ç¡®ç­‰äº '+str(expect_k)}ï¼›"
                 "ä¸å¾—è¿”å›é™¤ JSON ä»¥å¤–çš„ä»»ä½•æ–‡æœ¬ã€‚\n") +
                f"ã€é£æ ¼æç¤ºã€‘{style_preset(batch_index)}\n"
                f"ã€TTS è¯­è¨€æŒ‡çº¹ã€‘{tts_sig}\n"
                f"ã€Caption è¯­è¨€æŒ‡çº¹ã€‘{cap_sig}\n\n"
                "ã€TTS åŸæ–‡ã€‘\n" + tts_src + "\n\n" +
                "ã€ä¸‹æ–¹æ–‡æ¡ˆæ­£æ–‡ï¼ˆä¸å«æ ‡ç­¾ï¼‰ã€‘\n" + cap_body + "\n\n" +
                "ã€è¾“å‡º JSON æ¨¡æ¿ã€‘\n" + (template_single if expect_k==1 else template_multi) + "\n"
            )
        else:
            template_single = "{\n  \"caption\": \"æ”¹å†™åçš„ä¸‹æ–¹æ–‡æ¡ˆï¼ˆä¿æŒåŸè¯­è¨€/æ··åˆè¯­è¨€ï¼Œä¸ç¿»è¯‘ï¼›ä¸å«ä»»ä½•æ ‡ç­¾ï¼‰\"\n}"
            template_multi = "{\n  \"variants\": [\n    {\"caption\": \"...\"}\n  ]\n}"
            
            return (
                (f"ã€ä»»åŠ¡ã€‘æ­¤è½®ç”Ÿæˆ {expect_k} ä¸ªäº’ä¸é‡å¤çš„ Caption å˜ä½“ï¼›"
                 f"{'ç›´æ¥è¿”å›å•ä¸ªJSONå¯¹è±¡' if expect_k==1 else 'è¿”å›ä¸€ä¸ªåŒ…å« variants æ•°ç»„çš„ JSON å¯¹è±¡ï¼Œvariants é•¿åº¦å¿…é¡»ç²¾ç¡®ç­‰äº '+str(expect_k)}ï¼›"
                 "ä¸å¾—è¿”å›é™¤ JSON ä»¥å¤–çš„ä»»ä½•æ–‡æœ¬ã€‚\n") +
                f"ã€é£æ ¼æç¤ºã€‘{style_preset(batch_index)}\n"
                f"ã€Caption è¯­è¨€æŒ‡çº¹ã€‘{cap_sig}\n\n"
                "ã€ä¸‹æ–¹æ–‡æ¡ˆæ­£æ–‡ï¼ˆä¸å«æ ‡ç­¾ï¼‰ã€‘\n" + cap_body + "\n\n" +
                "ã€è¾“å‡º JSON æ¨¡æ¿ã€‘\n" + (template_single if expect_k==1 else template_multi) + "\n"
            )

    # System prompt varies with per-request setting and TTS availability
    if tts_src:
        system_prompt_single = (
            "ä½ æ˜¯çŸ­è§†é¢‘æ–‡æ¡ˆæ”¹å†™åŠ©æ‰‹ã€‚ä¸¥æ ¼è¾“å‡º jsonï¼ˆå•ä¸ªå¯¹è±¡ï¼Œä¸å¾—åŒ…å«æ•°ç»„æˆ– variants é”®ï¼‰ã€‚ç»“æ„ï¼š{\"tts\":\"...\",\"caption\":\"...\"}ã€‚\n"
            + language_rules + "\n" + base_rules
        )
        system_prompt_multi = (
            "ä½ æ˜¯çŸ­è§†é¢‘æ–‡æ¡ˆæ”¹å†™åŠ©æ‰‹ã€‚ä¸¥æ ¼è¾“å‡º jsonï¼ˆå¯¹è±¡å†…åŒ…å« variants æ•°ç»„ï¼‰ã€‚ç»“æ„ï¼š{\"variants\":[{\"tts\":\"...\",\"caption\":\"...\"}, ...]}ã€‚\n"
            "variants çš„é•¿åº¦å¿…é¡»ä¸æŒ‡ä»¤ä¸€è‡´ï¼Œä¸å¾—å¤šä¹Ÿä¸å¾—å°‘ã€‚\n"
            + language_rules + "\n" + base_rules
        )
    else:
        system_prompt_single = (
            "ä½ æ˜¯çŸ­è§†é¢‘æ–‡æ¡ˆæ”¹å†™åŠ©æ‰‹ã€‚ä¸¥æ ¼è¾“å‡º jsonï¼ˆå•ä¸ªå¯¹è±¡ï¼Œä¸å¾—åŒ…å«æ•°ç»„æˆ– variants é”®ï¼‰ã€‚ç»“æ„ï¼š{\"caption\":\"...\"}ã€‚\n"
            + language_rules + "\n" + base_rules
        )
        system_prompt_multi = (
            "ä½ æ˜¯çŸ­è§†é¢‘æ–‡æ¡ˆæ”¹å†™åŠ©æ‰‹ã€‚ä¸¥æ ¼è¾“å‡º jsonï¼ˆå¯¹è±¡å†…åŒ…å« variants æ•°ç»„ï¼‰ã€‚ç»“æ„ï¼š{\"variants\":[{\"caption\":\"...\"}, ...]}ã€‚\n"
            "variants çš„é•¿åº¦å¿…é¡»ä¸æŒ‡ä»¤ä¸€è‡´ï¼Œä¸å¾—å¤šä¹Ÿä¸å¾—å°‘ã€‚\n"
            + language_rules + "\n" + base_rules
        )

    total_needed = args.num
    per_req = max(1, args.variants_per_request)
    made = 0
    batch_index = 0
    global_variant_index = 0

    while made < total_needed:
        k = min(per_req, total_needed - made)  # last batch may be smaller
        batch_index += 1
        
        # Debug output
        print(f"\n[Debug] Batch {batch_index}: made={made}, total_needed={total_needed}, k={k}")

        system_prompt = system_prompt_multi if k > 1 else system_prompt_single
        user_prompt = build_user_prompt(batch_index-1, k)

        # call with retries
        raw = ""
        for attempt in range(args.retries + 1):
            try:
                if args.stream:
                    stream_log = Path(args.stream_log) if args.stream_log else None
                    raw = call_stream(
                        client, args.model, system_prompt, user_prompt,
                        show_reasoning=(not args.no_reasoning),
                        max_tokens=args.max_tokens,
                        temperature=args.temperature,
                        stream_style=args.stream_style,
                        stream_log=stream_log
                    )
                else:
                    raw = call_no_stream(
                        client, args.model, system_prompt, user_prompt,
                        max_tokens=args.max_tokens, temperature=args.temperature
                    )

                if not raw.strip():
                    raise RuntimeError("ç©ºå“åº”")
                data = robust_parse_json(raw)
                break
            except Exception as e:
                if attempt >= args.retries:
                    raise RuntimeError(f"è§£æå¤±è´¥ï¼ˆå·²é‡è¯• {args.retries} æ¬¡ï¼‰ã€‚åŸå§‹ç‰‡æ®µï¼š{raw[:800]}") from e
                time.sleep(1.2 * (attempt + 1))

        # normalize to variants list
        variants: List[Dict[str, str]] = []
        if k == 1:
            if isinstance(data, dict) and ("tts" in data or "caption" in data):
                variants = [data]
            elif isinstance(data, dict) and "variants" in data and isinstance(data["variants"], list) and len(data["variants"]) >= 1:
                variants = data["variants"][:1]
            else:
                raise RuntimeError(f"JSON ç»“æ„ä¸ç¬¦åˆå•å¯¹è±¡è¦æ±‚ï¼š{data}")
        else:
            if not (isinstance(data, dict) and isinstance(data.get("variants"), list)):
                raise RuntimeError(f"JSON ç»“æ„åº”åŒ…å« variants æ•°ç»„ï¼š{data}")
            if len(data["variants"]) != k:
                # tolerate overlong by trimming, or underlong by error
                if len(data["variants"]) > k:
                    variants = data["variants"][:k]
                else:
                    raise RuntimeError(f"variants é•¿åº¦ä¸ç¬¦ï¼ŒæœŸæœ› {k}ï¼Œå®é™… {len(data['variants'])}")
            else:
                variants = data["variants"]

        # write files
        print(f"\n[Debug] Writing {len(variants)} variants...")
        for item in variants:
            global_variant_index += 1
            
            # Handle TTS output if TTS is provided
            if tts_src and tts_dir:
                tts_out = (item.get("tts") or "").strip()
                # Preprocess TTS text to convert punctuation to newlines
                tts_out = preprocess_tts_text(tts_out)
                idx = f"{global_variant_index:02d}"
                (tts_dir / f"variant_{idx}_tts.txt").write_text(tts_out, encoding="utf-8")
                print(f"âœ“ TTS: {tts_dir / f'variant_{idx}_tts.txt'}")
            
            # Always handle caption output
            cap_out = (item.get("caption") or "").strip()
            if tags:
                cap_out = (cap_out + "\n" + " ".join(tags)).strip()

            idx = f"{global_variant_index:02d}"
            (cap_dir / f"variant_{idx}_caption.txt").write_text(cap_out, encoding="utf-8")
            print(f"âœ“ Caption: {cap_dir / f'variant_{idx}_caption.txt'}")

        made += len(variants)
        print(f"[Debug] Total made so far: {made}")

if __name__ == "__main__":
    main()
